{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: 5165 samples\n",
      "Synthetic dataset: 4516 samples\n",
      "Non-synthetic dataset: 649 samples\n",
      "English dataset: 2774 samples\n",
      "Non-English dataset: 2391 samples\n",
      "\n",
      "Question type statistics:\n",
      "nan dataset: 0 samples\n",
      "Multimodal content dataset: 635 samples\n",
      "Out-of-scope information dataset: 632 samples\n",
      "Other common hallucinated questions dataset: 668 samples\n",
      "Errors, contradictions, or unsolvable questions dataset: 620 samples\n",
      "Advanced logical reasoning dataset: 605 samples\n",
      "Default question type dataset: 1473 samples\n",
      "\n",
      "Hallucination type statistics:\n",
      "nan hallucination dataset: 0 samples\n",
      "Outdated information hallucination hallucination dataset: 285 samples\n",
      "Overclaim hallucination hallucination dataset: 419 samples\n",
      "Relation-error hallucination hallucination dataset: 642 samples\n",
      "Unverifiable information hallucination hallucination dataset: 228 samples\n",
      "Incompleteness hallucination hallucination dataset: 582 samples\n",
      "Entity-error hallucination hallucination dataset: 145 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the test dataset\n",
    "test_file_path = '/Users/jgilhuly/Documents/dev/GitHub/dataset-generation-research/combined_datasets_for_tuning/all_languages/test.csv'\n",
    "df = pd.read_csv(test_file_path)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = './temp'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Split into synthetic and non-synthetic datasets\n",
    "synthetic_df = df[df['synthetic'] == True]\n",
    "non_synthetic_df = df[df['synthetic'] == False]\n",
    "\n",
    "# Split into English and non-English datasets\n",
    "english_df = df[df['language'] == 'en']\n",
    "non_english_df = df[df['language'] != 'en']\n",
    "\n",
    "# Split by question_type\n",
    "question_types = df['question_type'].unique()\n",
    "question_type_dfs = {}\n",
    "for q_type in question_types:\n",
    "    question_type_dfs[q_type] = df[df['question_type'] == q_type]\n",
    "\n",
    "# Split by hallucination_type_realized\n",
    "hallucination_types = df['hallucination_type_realized'].unique()\n",
    "hallucination_type_dfs = {}\n",
    "for h_type in hallucination_types:\n",
    "    hallucination_type_dfs[h_type] = df[df['hallucination_type_realized'] == h_type]\n",
    "\n",
    "# Save the datasets\n",
    "synthetic_df.to_csv(os.path.join(output_dir, 'test_synthetic.csv'), index=False)\n",
    "non_synthetic_df.to_csv(os.path.join(output_dir, 'test_non_synthetic.csv'), index=False)\n",
    "english_df.to_csv(os.path.join(output_dir, 'test_english.csv'), index=False)\n",
    "non_english_df.to_csv(os.path.join(output_dir, 'test_non_english.csv'), index=False)\n",
    "\n",
    "# Save datasets by question_type\n",
    "for q_type, q_df in question_type_dfs.items():\n",
    "    q_df.to_csv(os.path.join(output_dir, f'test_{q_type}.csv'), index=False)\n",
    "\n",
    "# Save datasets by hallucination_type_realized\n",
    "for h_type, h_df in hallucination_type_dfs.items():\n",
    "    h_df.to_csv(os.path.join(output_dir, f'test_hallucination_{h_type}.csv'), index=False)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Original dataset: {len(df)} samples\")\n",
    "print(f\"Synthetic dataset: {len(synthetic_df)} samples\")\n",
    "print(f\"Non-synthetic dataset: {len(non_synthetic_df)} samples\")\n",
    "print(f\"English dataset: {len(english_df)} samples\")\n",
    "print(f\"Non-English dataset: {len(non_english_df)} samples\")\n",
    "\n",
    "# Print question_type statistics\n",
    "print(\"\\nQuestion type statistics:\")\n",
    "for q_type, q_df in question_type_dfs.items():\n",
    "    print(f\"{q_type} dataset: {len(q_df)} samples\")\n",
    "\n",
    "# Print hallucination_type_realized statistics\n",
    "print(\"\\nHallucination type statistics:\")\n",
    "for h_type, h_df in hallucination_type_dfs.items():\n",
    "    print(f\"{h_type} hallucination dataset: {len(h_df)} samples\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoenix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
