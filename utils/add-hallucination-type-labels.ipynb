{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was used to add hallucination type labels to the label_datasets using an ensemble of judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_prompt = \"\"\"\n",
    "    You are a helpful assistant that classifies hallucination types.\n",
    "    You will be given a text and you need to classify it into one of the following categories:\n",
    "\n",
    "    1 - Entity-error Hallucination. This type of hallucination refers to the situations where the generated text of LLMs contains erroneous entities, such\n",
    "    as person, date, location, and object, that contradict\n",
    "    with the world knowledge.\n",
    "    \n",
    "    2 - Relation-error Hallucination. This type of\n",
    "    hallucination refers to the generated text of LLMs\n",
    "    contains wrong relations between entities such as\n",
    "    quantitative and chronological relation.\n",
    "    \n",
    "    3 - Incompleteness Hallucination. LLMs might\n",
    "    exhibit incomplete output when generating lengthy\n",
    "    or listed responses. This hallucination arises when\n",
    "    LLMs are asked about aggregated facts and they\n",
    "    fail to reserve the factual completeness.\n",
    "    \n",
    "    4 - Outdatedness Hallucination. This type of\n",
    "    hallucination refers to situations where the generated content of LLMs is outdated for the present\n",
    "    moment, but was correct at some point in the past.\n",
    "    This issue arises primarily due to the fact that most\n",
    "    LLMs were trained on time-limited corpora\n",
    "    \n",
    "    5 - Overclaim Hallucination. This type of hallucination means that the statement expressed in\n",
    "    the generated text of LLMs is beyond the scale of\n",
    "    factual knowledge \n",
    "    \n",
    "    6 - Unverifiability Hallucination. In some cases,\n",
    "    the information generated by LLMs cannot be verified by available information sources.\n",
    "    \n",
    "    Only reply with the category number, no other text.\n",
    "    \n",
    "    Input:\n",
    "    {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from together import Together\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def get_llm_classification(text: str, client, model_type: str, max_retries: int = 1) -> str:\n",
    "    \"\"\"Make classification call to specific LLM with retries\"\"\"\n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            if model_type == \"openai\":\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": classification_prompt.format(text=text)}\n",
    "                    ]\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "            \n",
    "            elif model_type == \"anthropic\":\n",
    "                response = client.messages.create(\n",
    "                    model=\"claude-3-sonnet-20240229\",\n",
    "                    max_tokens=1000,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": classification_prompt.format(text=text)}\n",
    "                    ]\n",
    "                )\n",
    "                return response.content[0].text\n",
    "                \n",
    "            elif model_type == \"together\":\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-128K\",\n",
    "                    messages=[{\"role\": \"user\", \"content\": classification_prompt.format(text=text)}],\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "                \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries:\n",
    "                print(f\"Failed {model_type} call after {max_retries} retries: {e}\")\n",
    "                return \"1\"  # Default to entity error if all retries fail\n",
    "            \n",
    "    return \"1\"  # Default case\n",
    "\n",
    "def classify_hallucination_type(text: str) -> str:\n",
    "    \"\"\"Classify hallucination type using ensemble of LLM predictions\"\"\"\n",
    "    # Initialize clients\n",
    "    openai_client = OpenAI()\n",
    "    anthropic_client = anthropic.Anthropic()\n",
    "    together_client = Together()\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    responses = [\n",
    "        get_llm_classification(text, openai_client, \"openai\"),\n",
    "        get_llm_classification(text, anthropic_client, \"anthropic\"),\n",
    "        get_llm_classification(text, together_client, \"together\")\n",
    "    ]\n",
    "    \n",
    "    # Convert responses to integers and get majority vote\n",
    "    parsed_responses = []\n",
    "    for r in responses:\n",
    "        try:\n",
    "            # Try to convert to int, defaulting to 1 (entity error) if conversion fails\n",
    "            parsed_responses.append(int(r.strip()))\n",
    "        except ValueError:\n",
    "            print(f\"Could not parse response '{r}' as integer, defaulting to 1\")\n",
    "            parsed_responses.append(1)\n",
    "    \n",
    "    if not parsed_responses:\n",
    "        majority_vote = 1  # Default if no valid responses\n",
    "    else:\n",
    "        majority_vote = Counter(parsed_responses).most_common(1)[0][0]\n",
    "    \n",
    "    hallucination_types = {\n",
    "        1: \"Entity-error Hallucination\",\n",
    "        2: \"Relation-error Hallucination\", \n",
    "        3: \"Incompleteness Hallucination\",\n",
    "        4: \"Outdatedness Hallucination\",\n",
    "        5: \"Overclaim Hallucination\",\n",
    "        6: \"Unverifiability Hallucination\"\n",
    "    }\n",
    "    \n",
    "    return hallucination_types.get(majority_vote, \"Other hallucination\")\n",
    "\n",
    "def process_csv_files(directory: str):\n",
    "    \"\"\"Process CSV files and add hallucination type labels\"\"\"\n",
    "    for root, _, files in os.walk(directory):\n",
    "        # Skip directories with 'old' in the name\n",
    "        if 'old' in root.lower():\n",
    "            continue\n",
    "            \n",
    "        for file in tqdm(files, desc=\"Processing files\"):\n",
    "            if not file.endswith('.csv'):\n",
    "                continue\n",
    "                \n",
    "            file_path = os.path.join(root, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if 'hallucination_type_realized_ensemble' in df.columns:\n",
    "                print(f\"Skipping {file_path} - column already exists\")\n",
    "                continue\n",
    "            \n",
    "            # Add new column with hallucination type classifications\n",
    "            df['hallucination_type_realized_ensemble'] = None\n",
    "            hallucinated_mask = df['label'] == 'hallucinated'\n",
    "            hallucinated_rows = df[hallucinated_mask]\n",
    "            \n",
    "            # Process each hallucinated row\n",
    "            for idx, row in tqdm(hallucinated_rows.iterrows(), total=len(hallucinated_rows), desc=f\"Processing rows in {file}\"):\n",
    "                hallucination_type = classify_hallucination_type(\n",
    "                    f\"Reference: {row.reference}\\nOutput: {row.output}\"\n",
    "                )\n",
    "                df.loc[idx, 'hallucination_type_realized_ensemble'] = hallucination_type\n",
    "            \n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f\"Processed {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "process_csv_files(\"labeled_datasets/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoenix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
