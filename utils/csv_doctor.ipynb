{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if the csv files contain unreadable characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_unreadable_characters(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            file.read()\n",
    "        return False\n",
    "    except UnicodeDecodeError:\n",
    "        return True\n",
    "\n",
    "def test_csv_for_unreadable_characters(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                if contains_unreadable_characters(file_path):\n",
    "                    print(f\"File {file_path} contains unreadable characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_csv_for_unreadable_characters('labeled_datasets/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the csv files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csvs(directory, output_file):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    combined_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_csvs('labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals', 'combined_output/gpt-4o-synthetic-even.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the csv files to Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelbox_upload(csv_file_path, dataset_name):\n",
    "    import labelbox as lb\n",
    "\n",
    "    client = lb.Client(api_key=os.getenv(\"LABELBOX_API_KEY\"))\n",
    "\n",
    "    dataset = client.create_dataset(name=dataset_name)\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Create assets list\n",
    "    assets = []\n",
    "    for idx, row in df.iterrows():\n",
    "        asset = {\n",
    "            \"row_data\": \"Question: \" + str(row['input']) + '\\n' + \"Reference: \" + str(row['reference']) + '\\n' + \"Output: \" + str(row['output']),\n",
    "            \"global_key\": f\"{dataset_name}-{idx:04d}\",\n",
    "            \"media_type\": \"TEXT\",\n",
    "            \"metadata_fields\": [\n",
    "                {\n",
    "                    \"schema_id\": \"cko8s9r5v0001h2dk9elqdidh\",\n",
    "                    \"value\": \"synthetic\" if row['synthetic'] == 'True' else 'non_synthetic',\n",
    "                    \"language\": row['language'],\n",
    "                    \"rag_model\": row['rag_model'],\n",
    "                    \"force_even_split\": row['force_even_split'],\n",
    "                    \"synthetic\": row['synthetic'],\n",
    "                }\n",
    "            ],\n",
    "            \"attachments\": [\n",
    "                {\n",
    "                    \"type\": \"RAW_TEXT\",\n",
    "                    \"value\": \"Question: \" + str(row['input']) + '\\n' + \"Reference: \" + str(row['reference']) + '\\n' + \"Output: \" + str(row['output'])\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        assets.append(asset)\n",
    "\n",
    "    # Bulk add data rows to the dataset\n",
    "    task = dataset.create_data_rows(assets)\n",
    "\n",
    "\n",
    "    task.wait_till_done()\n",
    "    print(task.errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelbox_uploads():\n",
    "    labelbox_upload('combined_datasets_for_evals_rd3/non_synthetic_hallucinations_all_languages.csv', 'Non-synthetic hallucinations all languages')\n",
    "    labelbox_upload('combined_datasets_for_evals_rd3/synthetic_hallucinations_all_languages.csv', 'Synthetic hallucinations all languages')\n",
    "    labelbox_upload('combined_datasets_for_evals_rd3/non_synthetic_hallucinations_english.csv', 'Non-synthetic hallucinations english')\n",
    "    labelbox_upload('combined_datasets_for_evals_rd3/synthetic_hallucinations_english.csv', 'Synthetic hallucinations english')\n",
    "    labelbox_upload('combined_datasets_for_evals_rd3/non_synthetic_hallucinations_international.csv', 'Non-synthetic hallucinations international')\n",
    "    labelbox_upload('combined_datasets_for_evals_rd3/synthetic_hallucinations_international.csv', 'Synthetic hallucinations international')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append Metadata to Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cm47c7yjx5z5307229b40jlcg', 'global_key': 'synthetic-0016', 'row_data': 'Question: このページは何に使用しますか？\\nReference: ã\\\\x81\\\\x93ã\\\\x81®ã\\\\x83\\\\x9aã\\\\x83¼ã\\\\x82¸ã\\\\x82\\\\x92ä½¿ç\\\\x94¨ã\\\\x81\\\\x97ã\\\\x81¦ã\\\\x80\\\\x81ç\\\\x94\\\\x9fæ\\\\x88\\\\x90AI ã\\\\x82¨ã\\\\x83¼ã\\\\x82¸ã\\\\x82§ã\\\\x83³ã\\\\x83\\\\x88 ã\\\\x83\\\\x81ã\\\\x83¥ã\\\\x83¼ã\\\\x83\\\\x88ã\\\\x83ªã\\\\x82¢ã\\\\x83« (æ\\\\x97§ç§° AI ã\\\\x82¯ã\\\\x83\\\\x83ã\\\\x82¯ã\\\\x83\\\\x96ã\\\\x83\\\\x83ã\\\\x82¯) ã\\\\x82\\\\x92ã\\\\x83\\\\x8aã\\\\x83\\\\x93ã\\\\x82²ã\\\\x83¼ã\\\\x83\\\\x88ã\\\\x81\\\\x97ã\\\\x81¾ã\\\\x81\\\\x99ã\\\\x80\\\\x82ç«¯ã\\\\x81\\\\x8bã\\\\x82\\\\x89ç«¯ã\\\\x81¾ã\\\\x81§è¿½ã\\\\x81\\\\x84ã\\\\x81\\\\x8bã\\\\x81\\\\x91ã\\\\x82\\\\x8bã\\\\x81\\\\x8bã\\\\x80\\\\x81è\\\\x88\\\\x88å\\\\x91³ã\\\\x81®ã\\\\x81\\\\x82ã\\\\x82\\\\x8bé\\\\xa0\\\\x98å\\\\x9f\\\\x9fã\\\\x81«é£\\\\x9bã\\\\x81³è¾¼ã\\\\x82\\\\x93ã\\\\x81§ã\\\\x81\\\\x8fã\\\\x81\\\\xa0ã\\\\x81\\\\x95ã\\\\x81\\\\x84ã\\\\x80\\\\x82\\nOutput: 生成AIエージェント チュートリアル（旧称 AI クックブック）をナビゲートするために使用します。'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  14%|█▍        | 1440/10208 [00:01<00:05, 1500.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No label found for nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  22%|██▏       | 2199/10208 [00:01<00:05, 1493.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No label found for nan\n",
      "No label found for nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  25%|██▍       | 2503/10208 [00:01<00:05, 1497.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No label found for nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  32%|███▏      | 3271/10208 [00:02<00:04, 1519.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No label found for nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  59%|█████▉    | 6042/10208 [00:04<00:02, 1515.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No label found for nan\n",
      "No label found for nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  64%|██████▎   | 6496/10208 [00:04<00:02, 1474.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No label found for nan\n",
      "No label found for nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  71%|███████   | 7247/10208 [00:04<00:01, 1484.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No label found for nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  93%|█████████▎| 9540/10208 [00:06<00:00, 1506.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No label found for nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 10208/10208 [00:06<00:00, 1495.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DataUpsertTask ID: cdtopxefh073800mhm4kcuwqs>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import labelbox as lb\n",
    "import pandas as pd\n",
    "\n",
    "client = lb.Client(api_key=os.getenv(\"LABELBOX_API_KEY\"))\n",
    "\n",
    "# dataset = client.create_dataset(name=dataset_name)\n",
    "dataset = client.get_dataset(\"your dataset name\")\n",
    "metadata_ontology = client.get_data_row_metadata_ontology()\n",
    "tag_schema = metadata_ontology.get_by_name(\"tag\")\n",
    "\n",
    "labeled_df = pd.read_json('labelbox_datasets/Export v2 project - Hallucination Evaluation 3 - 12_11_2024.ndjson', lines=True)\n",
    "\n",
    "# print(tag_schema.uid)\n",
    "\n",
    "print(labeled_df.iloc[0]['data_row'])\n",
    "synthetic_df = pd.read_csv('combined_datasets_for_evals_rd2/synthetic_hallucinations_all_languages.csv')\n",
    "non_synthetic_df = pd.read_csv('combined_datasets_for_evals_rd2/non_synthetic_hallucinations_all_languages.csv')\n",
    "\n",
    "synthetic_data_rows = []\n",
    "non_synthetic_data_rows = []\n",
    "\n",
    "from tqdm import tqdm\n",
    "for index, row in tqdm(labeled_df.iterrows(), total=len(labeled_df), desc=\"Processing rows\"):\n",
    "    id = row['data_row']['id']\n",
    "    text = row['data_row'][\"row_data\"]\n",
    "    \n",
    "    # Parse the concatenated text back into its components\n",
    "    question_start = text.find(\"Question: \") + len(\"Question: \")\n",
    "    reference_start = text.find(\"Reference: \") + len(\"Reference: \")\n",
    "    output_start = text.find(\"Output: \") + len(\"Output: \")\n",
    "    \n",
    "    question = text[question_start:text.find(\"\\n\", question_start)]\n",
    "    reference = text[reference_start:text.find(\"\\n\", reference_start)]\n",
    "    output = text[output_start:]\n",
    "    \n",
    "    # Look for exact match of output in both dataframes\n",
    "    synthetic_match = synthetic_df[synthetic_df['output'] == output]\n",
    "    non_synthetic_match = non_synthetic_df[non_synthetic_df['output'] == output]\n",
    "    \n",
    "    # Get label if found in either dataset\n",
    "    label = None\n",
    "    if not synthetic_match.empty:\n",
    "        label = synthetic_match.iloc[0]['label']\n",
    "        explanation = synthetic_match.iloc[0]['explanation_mistral-large-latest']\n",
    "        match_type = 'synthetic'\n",
    "    if not non_synthetic_match.empty:\n",
    "        label = non_synthetic_match.iloc[0]['label']\n",
    "        explanation = non_synthetic_match.iloc[0]['explanation_mistral-large-latest']\n",
    "        match_type = 'non_synthetic'\n",
    "        \n",
    "    if label is None:\n",
    "        print(f\"No label found for {output}\")\n",
    "    else:\n",
    "        # print(f\"Label found for {output}: {label}\")\n",
    "        data = {\n",
    "            \"key\": lb.UniqueId(id),\n",
    "            \"metadata_fields\": [\n",
    "                lb.DataRowMetadataField(\n",
    "                    schema_id=tag_schema.uid,\n",
    "                    value=label + ' ' + explanation\n",
    "                ),\n",
    "            ]\n",
    "        }\n",
    "        if match_type == 'synthetic':\n",
    "            synthetic_data_rows.append(data)\n",
    "        else:\n",
    "            non_synthetic_data_rows.append(data)\n",
    "\n",
    "non_synthetic_dataset = client.get_dataset(\"cm47cjprz00tr0722gg155z9b\")\n",
    "non_synthetic_dataset.upsert_data_rows(non_synthetic_data_rows)\n",
    "\n",
    "synthetic_dataset = client.get_dataset(\"cm47c6top00qr07945g0rdn3r\")\n",
    "synthetic_dataset.upsert_data_rows(synthetic_data_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def labelbox_upload(csv_file_path, dataset_name, sample_size = None):\n",
    "    import labelbox as lb\n",
    "\n",
    "    # Read the CSV file\n",
    "    df_raw = pd.read_csv(csv_file_path)\n",
    "    df_filtered = df_raw[df_raw['label'] != 'NOT_PARSABLE']\n",
    "    \n",
    "    if sample_size is not None:\n",
    "        # Get equal samples for each combination of label and synthetic\n",
    "        samples = []\n",
    "\n",
    "        # Get counts for each combination, excluding NOT_PARSABLE\n",
    "        counts = df_filtered.groupby(['label', 'synthetic']).size()\n",
    "        min_count = min(counts)\n",
    "        target_per_group = min(min_count, 25) # 25 = 100/4 groups\n",
    "\n",
    "        samples = []\n",
    "        for label in df_filtered['label'].unique():\n",
    "            for synthetic in df_filtered['synthetic'].unique():\n",
    "                subset = df_filtered[(df_filtered['label'] == label) & (df_filtered['synthetic'] == synthetic)]\n",
    "                if len(subset) > 0:\n",
    "                    samples.append(subset.sample(n=target_per_group, random_state=31))\n",
    "        df = pd.concat(samples)\n",
    "    else:\n",
    "        df = df_filtered.copy()\n",
    "        \n",
    "    \n",
    "    df['common_explanation'] = df.apply(lambda row: row['explanation_gpt-4o'] if row['label_gpt-4o'] == row['label'] else row['explanation_claude-3-5-sonnet-latest'], axis=1)\n",
    "\n",
    "\n",
    "    client = lb.Client(api_key=os.getenv(\"LABELBOX_API_KEY\"))\n",
    "\n",
    "    dataset = client.create_dataset(name=dataset_name)\n",
    "\n",
    "    # Add data rows with metadata\n",
    "    data_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "            \n",
    "        # Create the data row\n",
    "        data_row = {\n",
    "            \"row_data\": \"Question: \" + str(row['input']) + '\\n\\n' + \"Reference: \" + str(row['reference']) + '\\n\\n' + \"Output: \" + str(row['output']),\n",
    "            \"external_id\": str(uuid.uuid4()),  # Unique ID for the row\n",
    "        }\n",
    "        data_rows.append(data_row)\n",
    "\n",
    "\n",
    "    # Bulk add data rows to the dataset\n",
    "    task = dataset.create_data_rows(data_rows)\n",
    "\n",
    "    task.wait_till_done()\n",
    "    print(task.errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z6/6g1hmm4x2dl0z84s6bwkgdzr0000gn/T/ipykernel_88596/3917772438.py:7: DtypeWarning: Columns (18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(csv_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "labelbox_upload('temp/english_only.csv', 'English hallucination sample - no labels', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload all rows to Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def labelbox_upload(csv_file_path, dataset_name, sample_size = None):\n",
    "    import labelbox as lb\n",
    "\n",
    "    # Read the CSV file\n",
    "    df_raw = pd.read_csv(csv_file_path)\n",
    "    df = df_raw[df_raw['label'] != 'NOT_PARSABLE'].copy()\n",
    "    \n",
    "    df['common_explanation'] = df.apply(lambda row: row['explanation_gpt-4o'] if row['label_gpt-4o'] == row['label'] else row['explanation_claude-3-5-sonnet-latest'], axis=1)\n",
    "\n",
    "    client = lb.Client(api_key=os.getenv(\"LABELBOX_API_KEY\"))\n",
    "\n",
    "    dataset = client.create_dataset(name=dataset_name)\n",
    "\n",
    "    # Add data rows with metadata\n",
    "    data_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "            \n",
    "        # Create the data row\n",
    "        data_row = {\n",
    "            \"row_data\": \"Question: \" + str(row['input']) + '\\n\\n' + \"Reference: \" + str(row['reference']) + '\\n\\n' + \"Output: \" + str(row['output']) + '\\n\\n' + \"Generated label: \" + str(row['label']) + '\\n\\n' + \"Explanation: \" + str(row['common_explanation']),\n",
    "            \"external_id\": str(uuid.uuid4()),  # Unique ID for the row\n",
    "        }\n",
    "        data_rows.append(data_row)\n",
    "\n",
    "\n",
    "    # Bulk add data rows to the dataset\n",
    "    task = dataset.create_data_rows(data_rows)\n",
    "\n",
    "    task.wait_till_done()\n",
    "    print(task.errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z6/6g1hmm4x2dl0z84s6bwkgdzr0000gn/T/ipykernel_81836/1741282643.py:7: DtypeWarning: Columns (6,7,8,9,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(csv_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "labelbox_upload('temp/all_datasets.csv', '1/4 - full dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Labelbox Data and existing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z6/6g1hmm4x2dl0z84s6bwkgdzr0000gn/T/ipykernel_88596/3771252308.py:9: DtypeWarning: Columns (18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  labeled_df = pd.read_csv('temp/english_only.csv')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import labelbox as lb\n",
    "import pandas as pd\n",
    "\n",
    "client = lb.Client(api_key=os.getenv(\"LABELBOX_API_KEY\"))\n",
    "\n",
    "# dataset = client.create_dataset(name=dataset_name)\n",
    "dataset = client.get_dataset(\"cm574n8g900ib0782k19g4ce7\")\n",
    "labeled_df = pd.read_csv('temp/english_only.csv')\n",
    "\n",
    "new_data_rows = []\n",
    "\n",
    "for row in dataset.data_rows():\n",
    "    # Split row_data back into input, output, reference\n",
    "    row_data = row.row_data\n",
    "    \n",
    "    # Extract the fields using string splitting\n",
    "    input_start = row_data.find(\"Question: \") + len(\"Question: \")\n",
    "    input_end = row_data.find(\"\\n\\n\", input_start)\n",
    "    input_text = row_data[input_start:input_end]\n",
    "    \n",
    "    ref_start = row_data.find(\"Reference: \") + len(\"Reference: \")\n",
    "    ref_end = row_data.find(\"\\n\\n\", ref_start) \n",
    "    reference = row_data[ref_start:ref_end]\n",
    "    \n",
    "    output_start = row_data.find(\"Output: \") + len(\"Output: \")\n",
    "    output = row_data[output_start:]\n",
    "    \n",
    "    # Find matching row in labeled_df by comparing input, output and reference\n",
    "    matching_row = labeled_df[\n",
    "        (labeled_df['input'] == input_text) & \n",
    "        (labeled_df['output'] == output) &\n",
    "        (labeled_df['reference'] == reference)\n",
    "    ]\n",
    "    \n",
    "    # If match found, get the label\n",
    "    if not matching_row.empty:\n",
    "        label = matching_row['label'].iloc[0]\n",
    "        row_data = row_data + '\\n\\n' + \"Generated label: \" + label\n",
    "        new_id = str(uuid.uuid4())\n",
    "        row.update(row_data=row_data, global_key=new_id)\n",
    "    \n",
    "    # new_data_row = {\n",
    "    #     \"row_data\": row['row_data'],\n",
    "    #     \"external_id\": row['external_id'],\n",
    "    #     \"metadata_fields\": metadata_fields\n",
    "    # }\n",
    "    # new_data_rows.append(new_data_row)\n",
    "\n",
    "# dataset.upsert_data_rows(new_data_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tuning data without full prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added tuning_data column to training and validation files\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from phoenix.evals import HALLUCINATION_PROMPT_TEMPLATE\n",
    "\n",
    "# Read the training and validation files\n",
    "train_df = pd.read_csv('train_Llama-3.2-1B-Instruct_en_tuning_data.csv')\n",
    "val_df = pd.read_csv('validation_Llama-3.2-1B-Instruct_en_tuning_data.csv')\n",
    "\n",
    "instruction_str = \"Query: {input}\\n\\nReference: {reference}\\n\\nAnswer: {output}\"\n",
    "\n",
    "def create_tuning_prompt(row):\n",
    "    return instruction_str.format(\n",
    "        input=row['input'],\n",
    "        output=row['output'],\n",
    "        reference=row['reference']\n",
    "    )\n",
    "\n",
    "# Add tuning_data column to both dataframes\n",
    "train_df['tuning_data_no_prompt'] = train_df.apply(create_tuning_prompt, axis=1)\n",
    "val_df['tuning_data_no_prompt'] = val_df.apply(create_tuning_prompt, axis=1)\n",
    "\n",
    "# Save the updated dataframes\n",
    "train_df.to_csv('train_Llama-3.2-1B-Instruct_en_tuning_data.csv', index=False)\n",
    "val_df.to_csv('validation_Llama-3.2-1B-Instruct_en_tuning_data.csv', index=False)\n",
    "\n",
    "print(\"Added tuning_data column to training and validation files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add rejected_label column to training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added tuning_data column to training and validation files\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the training and validation files\n",
    "train_df = pd.read_csv('train_Llama-3.2-1B-Instruct_en_tuning_data.csv')\n",
    "\n",
    "# Add tuning_data column to both dataframes\n",
    "train_df['rejected_label'] = train_df['label'].apply(lambda x: 'factual' if x == 'hallucinated' else 'hallucinated')\n",
    "\n",
    "# Save the updated dataframes\n",
    "train_df.to_csv('train_Llama-3.2-1B-Instruct_en_tuning_data.csv', index=False)\n",
    "\n",
    "print(\"Added rejected_label column to training file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicates from all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing synthetic_english.csv...\n",
      "Original number of rows: 25968\n",
      "Number of rows after removing duplicates: 16366\n",
      "Number of duplicate rows removed: 9602\n",
      "Saved unique rows to temp/synthetic_english_unique.csv\n",
      "\n",
      "Processing non_synthetic_english.csv...\n",
      "Original number of rows: 21906\n",
      "Number of rows after removing duplicates: 10871\n",
      "Number of duplicate rows removed: 11035\n",
      "Saved unique rows to temp/non_synthetic_english_unique.csv\n",
      "\n",
      "Processing synthetic_only.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z6/6g1hmm4x2dl0z84s6bwkgdzr0000gn/T/ipykernel_68759/1367541336.py:11: DtypeWarning: Columns (18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'temp/{csv_file}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows: 40188\n",
      "Number of rows after removing duplicates: 30509\n",
      "Number of duplicate rows removed: 9679\n",
      "Saved unique rows to temp/synthetic_only_unique.csv\n",
      "\n",
      "Processing non_synthetic_only.csv...\n",
      "Original number of rows: 29446\n",
      "Number of rows after removing duplicates: 18074\n",
      "Number of duplicate rows removed: 11372\n",
      "Saved unique rows to temp/non_synthetic_only_unique.csv\n",
      "\n",
      "Processing english_only.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z6/6g1hmm4x2dl0z84s6bwkgdzr0000gn/T/ipykernel_68759/1367541336.py:11: DtypeWarning: Columns (18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'temp/{csv_file}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows: 47874\n",
      "Number of rows after removing duplicates: 26934\n",
      "Number of duplicate rows removed: 20940\n",
      "Saved unique rows to temp/english_only_unique.csv\n",
      "\n",
      "Processing all_datasets.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z6/6g1hmm4x2dl0z84s6bwkgdzr0000gn/T/ipykernel_68759/1367541336.py:11: DtypeWarning: Columns (18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'temp/{csv_file}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows: 69634\n",
      "Number of rows after removing duplicates: 48105\n",
      "Number of duplicate rows removed: 21529\n",
      "Saved unique rows to temp/all_datasets_unique.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Get all CSV files in temp directory\n",
    "csv_files = [f for f in os.listdir('temp') if f.endswith('.csv')]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    print(f\"\\nProcessing {csv_file}...\")\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(f'temp/{csv_file}')\n",
    "    \n",
    "    # Drop duplicates based on input, reference, and output columns combined\n",
    "    df_unique = df.drop_duplicates(subset=['input', 'reference', 'output'])\n",
    "    \n",
    "    print(f\"Original number of rows: {len(df)}\")\n",
    "    print(f\"Number of rows after removing duplicates: {len(df_unique)}\")\n",
    "    print(f\"Number of duplicate rows removed: {len(df) - len(df_unique)}\")\n",
    "    \n",
    "    # Save unique rows to new file with _unique suffix\n",
    "    output_file = f'temp/{csv_file.replace(\".csv\", \"_unique.csv\")}'\n",
    "    df_unique.to_csv(output_file, index=False)\n",
    "    print(f\"Saved unique rows to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep csv for together instruct training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Dataset Statistics:\n",
      "Total rows: 34344\n",
      "\n",
      "Synthetic data distribution:\n",
      "label\n",
      "hallucinated    14936\n",
      "factual         14936\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Non-synthetic data distribution:\n",
      "label\n",
      "hallucinated    2236\n",
      "factual         2236\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('temp/all_datasets_unique.csv', low_memory=False)\n",
    "\n",
    "# Split into synthetic and non-synthetic\n",
    "synthetic_df = df[df['synthetic'] == True]\n",
    "non_synthetic_df = df[df['synthetic'] == False]\n",
    "\n",
    "# For synthetic data, get equal numbers of hallucinated and factual\n",
    "synthetic_hallucinated = synthetic_df[synthetic_df['label'] == 'hallucinated']\n",
    "synthetic_factual = synthetic_df[synthetic_df['label'] == 'factual']\n",
    "min_synthetic_count = min(len(synthetic_hallucinated), len(synthetic_factual))\n",
    "balanced_synthetic = pd.concat([\n",
    "    synthetic_hallucinated.sample(n=min_synthetic_count, random_state=42),\n",
    "    synthetic_factual.sample(n=min_synthetic_count, random_state=42)\n",
    "])\n",
    "\n",
    "# For non-synthetic data, get equal numbers of hallucinated and factual\n",
    "non_synthetic_hallucinated = non_synthetic_df[non_synthetic_df['label'] == 'hallucinated'] \n",
    "non_synthetic_factual = non_synthetic_df[non_synthetic_df['label'] == 'factual']\n",
    "min_non_synthetic_count = min(len(non_synthetic_hallucinated), len(non_synthetic_factual))\n",
    "balanced_non_synthetic = pd.concat([\n",
    "    non_synthetic_hallucinated.sample(n=min_non_synthetic_count, random_state=42),\n",
    "    non_synthetic_factual.sample(n=min_non_synthetic_count, random_state=42)\n",
    "])\n",
    "\n",
    "# Combine balanced datasets\n",
    "balanced_df = pd.concat([balanced_synthetic, balanced_non_synthetic])\n",
    "\n",
    "# Print statistics about the balanced dataset\n",
    "print(\"Balanced Dataset Statistics:\")\n",
    "print(f\"Total rows: {len(balanced_df)}\")\n",
    "print(\"\\nSynthetic data distribution:\")\n",
    "print(balanced_df[balanced_df['synthetic'] == True]['label'].value_counts())\n",
    "print(\"\\nNon-synthetic data distribution:\")\n",
    "print(balanced_df[balanced_df['synthetic'] == False]['label'].value_counts())\n",
    "\n",
    "# Save balanced dataset\n",
    "# balanced_df.to_csv('temp/balanced_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split Statistics:\n",
      "Training set size: 24040\n",
      "Validation set size: 5152\n",
      "Test set size: 5152\n",
      "\n",
      "Training set label distribution:\n",
      "label\n",
      "factual         12020\n",
      "hallucinated    12020\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation set label distribution:\n",
      "label\n",
      "hallucinated    2576\n",
      "factual         2576\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set label distribution:\n",
      "label\n",
      "hallucinated    2576\n",
      "factual         2576\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Calculate sizes for splits (70% train, 15% validation, 15% test)\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "# Split data by label to maintain balance\n",
    "hallucinated = balanced_df[balanced_df['label'] == 'hallucinated']\n",
    "factual = balanced_df[balanced_df['label'] == 'factual']\n",
    "\n",
    "# For each label, split into train/val/test\n",
    "def split_stratified(df):\n",
    "    # First split out test set\n",
    "    train_val, test = train_test_split(df, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Then split remaining data into train/val\n",
    "    # We need to adjust validation size to be relative to remaining data\n",
    "    relative_val_size = val_size / (train_size + val_size)\n",
    "    train, val = train_test_split(train_val, test_size=relative_val_size, random_state=42)\n",
    "    \n",
    "    return train, val, test\n",
    "\n",
    "# Split each label group\n",
    "hallucinated_train, hallucinated_val, hallucinated_test = split_stratified(hallucinated)\n",
    "factual_train, factual_val, factual_test = split_stratified(factual)\n",
    "\n",
    "# Combine splits while maintaining balance\n",
    "train_df = pd.concat([hallucinated_train, factual_train])\n",
    "val_df = pd.concat([hallucinated_val, factual_val]) \n",
    "test_df = pd.concat([hallucinated_test, factual_test])\n",
    "\n",
    "# Shuffle each split\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_df = val_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print statistics about the splits\n",
    "print(\"\\nSplit Statistics:\")\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "\n",
    "print(\"\\nTraining set label distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(\"\\nValidation set label distribution:\")\n",
    "print(val_df['label'].value_counts())\n",
    "print(\"\\nTest set label distribution:\")\n",
    "print(test_df['label'].value_counts())\n",
    "\n",
    "# Save splits to files\n",
    "train_df.to_csv('temp/1-17/train.csv', index=False)\n",
    "val_df.to_csv('temp/1-17/val.csv', index=False)\n",
    "test_df.to_csv('temp/1-17/test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted CSV files to JSONL format\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from phoenix.evals import HALLUCINATION_PROMPT_TEMPLATE\n",
    "\n",
    "def convert_to_jsonl(input_csv, output_jsonl):\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Open output file\n",
    "    with open(output_jsonl, 'w') as f:\n",
    "        # Process each row\n",
    "        for _, row in df.iterrows():\n",
    "            # Format prompt template with row data\n",
    "            prompt = HALLUCINATION_PROMPT_TEMPLATE.template.format(\n",
    "                input=row['input'],\n",
    "                reference=row['reference'], \n",
    "                output=row['output']\n",
    "            )\n",
    "            \n",
    "            # Create json object\n",
    "            json_obj = {\n",
    "                'prompt': prompt,\n",
    "                'completion': row['label']\n",
    "            }\n",
    "            \n",
    "            # Write to file\n",
    "            f.write(json.dumps(json_obj) + '\\n')\n",
    "\n",
    "# Convert train and test sets\n",
    "convert_to_jsonl('temp/1-17/train.csv', 'temp/1-17/train.jsonl')\n",
    "convert_to_jsonl('temp/1-17/test.csv', 'temp/1-17/test.jsonl')\n",
    "convert_to_jsonl('temp/1-17/val.csv', 'temp/1-17/val.jsonl')\n",
    "\n",
    "print(\"Converted CSV files to JSONL format\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Human Labels to Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "CSV_PATH = 'temp/all_datasets.csv'\n",
    "LB_API_KEY = os.getenv(\"LABELBOX_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download files from Labelbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Task cm6h8l76000ww07x60726a28j does not have a RESULT stream",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjson_stream_handler\u001b[39m(output: labelbox\u001b[38;5;241m.\u001b[39mBufferedJsonConverterOutput):\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mjson)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mexport_task\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_buffered_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabelbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStreamType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRESULT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstart(stream_handler\u001b[38;5;241m=\u001b[39mjson_stream_handler)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Simplified usage\u001b[39;00m\n\u001b[1;32m     13\u001b[0m export_json \u001b[38;5;241m=\u001b[39m [data_row\u001b[38;5;241m.\u001b[39mjson \u001b[38;5;28;01mfor\u001b[39;00m data_row \u001b[38;5;129;01min\u001b[39;00m export_task\u001b[38;5;241m.\u001b[39mget_buffered_stream()]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/phoenix/lib/python3.11/site-packages/labelbox/schema/export_task.py:576\u001b[0m, in \u001b[0;36mExportTask.get_buffered_stream\u001b[0;34m(self, stream_type)\u001b[0m\n\u001b[1;32m    572\u001b[0m metadata_header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_header(\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task\u001b[38;5;241m.\u001b[39mclient, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task\u001b[38;5;241m.\u001b[39muid, stream_type\n\u001b[1;32m    574\u001b[0m )\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata_header \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task\u001b[38;5;241m.\u001b[39muid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not have a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstream_type\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m stream\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BufferedStream(\n\u001b[1;32m    580\u001b[0m     _TaskContext(\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task\u001b[38;5;241m.\u001b[39mclient, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task\u001b[38;5;241m.\u001b[39muid, stream_type, metadata_header\n\u001b[1;32m    582\u001b[0m     ),\n\u001b[1;32m    583\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Task cm6h8l76000ww07x60726a28j does not have a RESULT stream"
     ]
    }
   ],
   "source": [
    "import labelbox\n",
    "\n",
    "client = labelbox.Client(api_key = LB_API_KEY)\n",
    "export_task = labelbox.ExportTask.get_task(client, \"cm6h8l76000ww07x60726a28j\")\n",
    "\n",
    "# Stream the export using a callback function\n",
    "def json_stream_handler(output: labelbox.BufferedJsonConverterOutput):\n",
    "  print(output.json)\n",
    "\n",
    "export_task.get_buffered_stream(stream_type=labelbox.StreamType.RESULT).start(stream_handler=json_stream_handler)\n",
    "\n",
    "# Simplified usage\n",
    "export_json = [data_row.json for data_row in export_task.get_buffered_stream()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse rows from Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 parsed entries:\n",
      "{'question': 'MongoDBのコレクションの構造を視覚的に説明した図を見せてもらえますか？', 'reference': 'コレクション: MongoDB はドキュメントをコレクションに保存します。 関係データベースのテーブルに類似しています。', 'answer': '申し訳ありませんが、この文脈からは視覚的な図を提供することはできません。コレクションは関係データベースのテーブルに似た構造で、ドキュメントを保存する場所であるということしか説明されていません。', 'label': 'factual', 'explanation': 'The query asks for a visual representation of the structure of a MongoDB collection. The reference text provides a brief description of a MongoDB collection, stating that it stores documents and is similar to a table in a relational database. However, it does not provide any visual representation or diagram. The answer correctly states that a visual diagram cannot be provided based on the given context and accurately describes the information available in the reference text, which is that a collection is similar to a table in a relational database and is a place where documents are stored. Therefore, the answer is consistent with the information provided in the reference text and does not introduce any false information.', 'hallucination_label': 'factual'}\n",
      "{'question': 'この記事では何について述べていますか？', 'reference': 'ã\\\\x81\\\\x93ã\\\\x81®è¨\\\\x98äº\\\\x8bã\\\\x81§ã\\\\x81¯ã\\\\x80\\\\x81æ©\\\\x9fè\\\\x83½ã\\\\x81®å\\\\x8f¯ç\\\\x94¨æ\\\\x80§ã\\\\x81«å\\\\x9c°å\\\\x9f\\\\x9få·®ã\\\\x81\\\\x8cã\\\\x81\\\\x82ã\\\\x82\\\\x8bæ©\\\\x9fè\\\\x83½ã\\\\x81®ä¸\\\\x80è¦§ã\\\\x82\\\\x92ç¤ºã\\\\x81\\\\x97ã\\\\x81¾ã\\\\x81\\\\x99ã\\\\x80\\\\x82', 'answer': '機能の可用性に地域差がある機能の一覧。', 'label': 'factual', 'explanation': 'The query asks what the article is about. The reference text states that the article provides an overview of functions with regional differences in availability. The answer given is \"機能の可用性に地域差がある機能の一覧。\" which translates to \"A list of functions with regional differences in availability.\" This matches the information provided in the reference text, as both mention the regional differences in the availability of functions. Therefore, the answer accurately reflects the content described in the reference text.'}\n",
      "{'question': 'Can you provide any images or examples of how you help make laws more accessible and understandable to the general public?', 'reference': 'We believe that everyone should be able to read and understand the laws that govern them, without cost. We carry out this vision by', 'answer': 'Based on the incomplete context provided, I cannot provide specific examples or images of how laws are made more accessible, as the context cuts off mid-sentence and does not contain complete information about the methods used.', 'label': 'factual', 'explanation': \"The query asks for images or examples of how laws are made more accessible and understandable to the general public. The reference text states a belief that everyone should be able to read and understand the laws that govern them without cost, but it cuts off before providing any specific methods or examples of how this is achieved. The answer correctly identifies that the context is incomplete and does not provide specific examples or images, which aligns with the reference text's lack of detailed information. Therefore, the answer is consistent with the reference text and does not introduce any fabricated information.\", 'hallucination_label': 'factual'}\n"
     ]
    }
   ],
   "source": [
    "parsed_data = []\n",
    "\n",
    "for row in export_json:\n",
    "    # Extract base data\n",
    "    row_data = row['data_row']['row_data']\n",
    "    # Parse the string to extract fields\n",
    "    data_dict = {}\n",
    "    \n",
    "    # Split by newlines in case fields span multiple lines\n",
    "    # Find the starting positions of each field\n",
    "    question_pos = row_data.find('Question:')\n",
    "    reference_pos = row_data.find('Reference:') \n",
    "    output_pos = row_data.find('Output:')\n",
    "    label_pos = row_data.find('Generated label:')\n",
    "    explanation_pos = row_data.find('Explanation:')\n",
    "    \n",
    "    # Create list of tuples with position and field name, sorted by position\n",
    "    field_positions = []\n",
    "    if question_pos != -1:\n",
    "        field_positions.append((question_pos, 'question', 'Question:'))\n",
    "    if reference_pos != -1:\n",
    "        field_positions.append((reference_pos, 'reference', 'Reference:'))\n",
    "    if output_pos != -1:\n",
    "        field_positions.append((output_pos, 'answer', 'Output:'))\n",
    "    if label_pos != -1:\n",
    "        field_positions.append((label_pos, 'label', 'Generated label:'))\n",
    "    if explanation_pos != -1:\n",
    "        field_positions.append((explanation_pos, 'explanation', 'Explanation:'))\n",
    "    \n",
    "    field_positions.sort()  # Sort by position\n",
    "    \n",
    "    # Extract text between positions\n",
    "    for i in range(len(field_positions)):\n",
    "        start_pos, field_name, prefix = field_positions[i]\n",
    "        # Get end position (either next field or end of string)\n",
    "        end_pos = field_positions[i+1][0] if i < len(field_positions)-1 else len(row_data)\n",
    "        \n",
    "        # Extract and clean the text\n",
    "        text = row_data[start_pos:end_pos]\n",
    "        text = text.replace(prefix, '', 1).strip()  # Remove the prefix only once\n",
    "        data_dict[field_name] = text\n",
    "    \n",
    "    # Set defaults for any missing fields\n",
    "    data_dict.setdefault('question', '')\n",
    "    data_dict.setdefault('reference', '')\n",
    "    data_dict.setdefault('answer', '')\n",
    "    data_dict.setdefault('label', '')\n",
    "    data_dict.setdefault('explanation', '')\n",
    "    \n",
    "    # Extract hallucination label from classifications\n",
    "    try:\n",
    "        classifications = row['projects']['cm5lqrlnv06vw07xx4ialh3gf']['labels'][0]['annotations']['classifications']\n",
    "        for classification in classifications:\n",
    "            if classification['name'] == 'Human Hallucination Label':\n",
    "                data_dict['hallucination_label'] = classification['radio_answer']['value']\n",
    "                break\n",
    "    except (KeyError, IndexError):\n",
    "        data_dict['hallucination_label'] = None\n",
    "        \n",
    "    parsed_data.append(data_dict)\n",
    "\n",
    "# Print first few entries to verify\n",
    "print(\"First 3 parsed entries:\")\n",
    "for entry in parsed_data[:3]:\n",
    "    print(entry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find matching rows in CSV and add human label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z6/6g1hmm4x2dl0z84s6bwkgdzr0000gn/T/ipykernel_254/2118970366.py:3: DtypeWarning: Columns (18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(CSV_PATH)\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Convert parsed_data to DataFrame for easier comparison\n",
    "parsed_df = pd.DataFrame(parsed_data)\n",
    "\n",
    "# Iterate through parsed data and update CSV rows\n",
    "for parsed_row in parsed_data:\n",
    "    matching_rows = df[\n",
    "        (df['input'] == parsed_row['question']) & \n",
    "        (df['reference'] == parsed_row['reference']) &\n",
    "        (df['output'] == parsed_row['answer'])\n",
    "    ]\n",
    "    \n",
    "    if not matching_rows.empty and parsed_row.get('hallucination_label') is not None:\n",
    "        # Update all matching rows with the hallucination label\n",
    "        df.loc[matching_rows.index, 'human_label'] = parsed_row['hallucination_label']\n",
    "\n",
    "# Save updated DataFrame back to CSV\n",
    "df.to_csv(CSV_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze Human Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts of human labels:\n",
      "human_label\n",
      "NaN             58154\n",
      "factual          7202\n",
      "hallucinated     4278\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Disagreement analysis between human labels and original labels:\n",
      "Total rows with human labels: 11480\n",
      "Number of disagreements: 563\n",
      "Number of agreements: 10917\n",
      "Disagreement rate: 4.90%\n",
      "\n",
      "Detailed breakdown of label comparisons:\n",
      "human_label   factual  hallucinated    All\n",
      "label                                     \n",
      "NOT_PARSABLE        2             5      7\n",
      "factual          6975           331   7306\n",
      "hallucinated      225          3942   4167\n",
      "All              7202          4278  11480\n"
     ]
    }
   ],
   "source": [
    "# Display value counts of human labels\n",
    "print(\"Value counts of human labels:\")\n",
    "print(df['human_label'].value_counts(dropna=False))\n",
    "\n",
    "# Calculate disagreement between human labels and original labels\n",
    "print(\"\\nDisagreement analysis between human labels and original labels:\")\n",
    "# Filter out rows where human_label is NaN\n",
    "df_valid = df[df['human_label'].notna()]\n",
    "disagreements = (df_valid['human_label'] != df_valid['label']).sum()\n",
    "total_human_labels = len(df_valid)\n",
    "agreement = (df_valid['human_label'] == df_valid['label']).sum()\n",
    "\n",
    "print(f\"Total rows with human labels: {total_human_labels}\")\n",
    "print(f\"Number of disagreements: {disagreements}\")\n",
    "print(f\"Number of agreements: {agreement}\")\n",
    "print(f\"Disagreement rate: {(disagreements/total_human_labels*100):.2f}%\")\n",
    "\n",
    "# Show confusion matrix of labels\n",
    "print(\"\\nDetailed breakdown of label comparisons:\")\n",
    "comparison_df = pd.crosstab(df_valid['label'], df_valid['human_label'], margins=True)\n",
    "print(comparison_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine human labels with labeled_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 parsed entries:\n",
      "{'question': 'MongoDBのコレクションの構造を視覚的に説明した図を見せてもらえますか？', 'reference': 'コレクション: MongoDB はドキュメントをコレクションに保存します。 関係データベースのテーブルに類似しています。', 'answer': '申し訳ありませんが、この文脈からは視覚的な図を提供することはできません。コレクションは関係データベースのテーブルに似た構造で、ドキュメントを保存する場所であるということしか説明されていません。', 'label': 'factual', 'explanation': 'The query asks for a visual representation of the structure of a MongoDB collection. The reference text provides a brief description of a MongoDB collection, stating that it stores documents and is similar to a table in a relational database. However, it does not provide any visual representation or diagram. The answer correctly states that a visual diagram cannot be provided based on the given context and accurately describes the information available in the reference text, which is that a collection is similar to a table in a relational database and is a place where documents are stored. Therefore, the answer is consistent with the information provided in the reference text and does not introduce any false information.', 'human_label': 'factual'}\n",
      "{'question': 'この記事では何について述べていますか？', 'reference': 'ã\\\\x81\\\\x93ã\\\\x81®è¨\\\\x98äº\\\\x8bã\\\\x81§ã\\\\x81¯ã\\\\x80\\\\x81æ©\\\\x9fè\\\\x83½ã\\\\x81®å\\\\x8f¯ç\\\\x94¨æ\\\\x80§ã\\\\x81«å\\\\x9c°å\\\\x9f\\\\x9få·®ã\\\\x81\\\\x8cã\\\\x81\\\\x82ã\\\\x82\\\\x8bæ©\\\\x9fè\\\\x83½ã\\\\x81®ä¸\\\\x80è¦§ã\\\\x82\\\\x92ç¤ºã\\\\x81\\\\x97ã\\\\x81¾ã\\\\x81\\\\x99ã\\\\x80\\\\x82', 'answer': '機能の可用性に地域差がある機能の一覧。', 'label': 'factual', 'explanation': 'The query asks what the article is about. The reference text states that the article provides an overview of functions with regional differences in availability. The answer given is \"機能の可用性に地域差がある機能の一覧。\" which translates to \"A list of functions with regional differences in availability.\" This matches the information provided in the reference text, as both mention the regional differences in the availability of functions. Therefore, the answer accurately reflects the content described in the reference text.'}\n",
      "{'question': 'Can you provide any images or examples of how you help make laws more accessible and understandable to the general public?', 'reference': 'We believe that everyone should be able to read and understand the laws that govern them, without cost. We carry out this vision by', 'answer': 'Based on the incomplete context provided, I cannot provide specific examples or images of how laws are made more accessible, as the context cuts off mid-sentence and does not contain complete information about the methods used.', 'label': 'factual', 'explanation': \"The query asks for images or examples of how laws are made more accessible and understandable to the general public. The reference text states a belief that everyone should be able to read and understand the laws that govern them without cost, but it cuts off before providing any specific methods or examples of how this is achieved. The answer correctly identifies that the context is incomplete and does not provide specific examples or images, which aligns with the reference text's lack of detailed information. Therefore, the answer is consistent with the reference text and does not introduce any fabricated information.\", 'human_label': 'factual'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "parsed_data = []\n",
    "export_json = pd.read_json('raw_human_labels.ndjson', lines=True)\n",
    "\n",
    "for _, row in export_json.iterrows():\n",
    "    # Extract base data\n",
    "    row_data = row['data_row']['row_data']\n",
    "    # Parse the string to extract fields\n",
    "    data_dict = {}\n",
    "    \n",
    "    # Split by newlines in case fields span multiple lines\n",
    "    # Find the starting positions of each field\n",
    "    question_pos = row_data.find('Question:')\n",
    "    reference_pos = row_data.find('Reference:') \n",
    "    output_pos = row_data.find('Output:')\n",
    "    label_pos = row_data.find('Generated label:')\n",
    "    explanation_pos = row_data.find('Explanation:')\n",
    "    \n",
    "    # Create list of tuples with position and field name, sorted by position\n",
    "    field_positions = []\n",
    "    if question_pos != -1:\n",
    "        field_positions.append((question_pos, 'question', 'Question:'))\n",
    "    if reference_pos != -1:\n",
    "        field_positions.append((reference_pos, 'reference', 'Reference:'))\n",
    "    if output_pos != -1:\n",
    "        field_positions.append((output_pos, 'answer', 'Output:'))\n",
    "    if label_pos != -1:\n",
    "        field_positions.append((label_pos, 'label', 'Generated label:'))\n",
    "    if explanation_pos != -1:\n",
    "        field_positions.append((explanation_pos, 'explanation', 'Explanation:'))\n",
    "    \n",
    "    field_positions.sort()  # Sort by position\n",
    "    \n",
    "    # Extract text between positions\n",
    "    for i in range(len(field_positions)):\n",
    "        start_pos, field_name, prefix = field_positions[i]\n",
    "        # Get end position (either next field or end of string)\n",
    "        end_pos = field_positions[i+1][0] if i < len(field_positions)-1 else len(row_data)\n",
    "        \n",
    "        # Extract and clean the text\n",
    "        text = row_data[start_pos:end_pos]\n",
    "        text = text.replace(prefix, '', 1).strip()  # Remove the prefix only once\n",
    "        data_dict[field_name] = text\n",
    "    \n",
    "    # Set defaults for any missing fields\n",
    "    data_dict.setdefault('question', '')\n",
    "    data_dict.setdefault('reference', '')\n",
    "    data_dict.setdefault('answer', '')\n",
    "    data_dict.setdefault('label', '')\n",
    "    data_dict.setdefault('explanation', '')\n",
    "    \n",
    "    # Extract hallucination label from classifications\n",
    "    try:\n",
    "        classifications = row['projects']['cm5lqrlnv06vw07xx4ialh3gf']['labels'][0]['annotations']['classifications']\n",
    "        for classification in classifications:\n",
    "            if classification['name'] == 'Human Hallucination Label':\n",
    "                data_dict['human_label'] = classification['radio_answer']['value']\n",
    "                break\n",
    "    except (KeyError, IndexError):\n",
    "        data_dict['human_label'] = None\n",
    "        \n",
    "    parsed_data.append(data_dict)\n",
    "\n",
    "# Print first few entries to verify\n",
    "print(\"First 3 parsed entries:\")\n",
    "for entry in parsed_data[:3]:\n",
    "    print(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference</th>\n",
       "      <th>answer</th>\n",
       "      <th>label</th>\n",
       "      <th>explanation</th>\n",
       "      <th>human_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MongoDBのコレクションの構造を視覚的に説明した図を見せてもらえますか？</td>\n",
       "      <td>コレクション: MongoDB はドキュメントをコレクションに保存します。 関係データベース...</td>\n",
       "      <td>申し訳ありませんが、この文脈からは視覚的な図を提供することはできません。コレクションは関係デ...</td>\n",
       "      <td>factual</td>\n",
       "      <td>The query asks for a visual representation of ...</td>\n",
       "      <td>factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>この記事では何について述べていますか？</td>\n",
       "      <td>ã\\x81\\x93ã\\x81®è¨\\x98äº\\x8bã\\x81§ã\\x81¯ã\\x80\\x...</td>\n",
       "      <td>機能の可用性に地域差がある機能の一覧。</td>\n",
       "      <td>factual</td>\n",
       "      <td>The query asks what the article is about. The ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you provide any images or examples of how ...</td>\n",
       "      <td>We believe that everyone should be able to rea...</td>\n",
       "      <td>Based on the incomplete context provided, I ca...</td>\n",
       "      <td>factual</td>\n",
       "      <td>The query asks for images or examples of how l...</td>\n",
       "      <td>factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When did Sabrina Karl join the Investopedia st...</td>\n",
       "      <td>Sabrina Karl joined the Investopedia staff in ...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>factual</td>\n",
       "      <td>To determine if the answer is factual or hallu...</td>\n",
       "      <td>factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>¿Cómo podría un algoritmo de aprendizaje autom...</td>\n",
       "      <td>Una cohort es un grupo de personas que compart...</td>\n",
       "      <td>El algoritmo podría utilizar técnicas de apren...</td>\n",
       "      <td>hallucinated</td>\n",
       "      <td>The query asks how a machine learning algorith...</td>\n",
       "      <td>factual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0             MongoDBのコレクションの構造を視覚的に説明した図を見せてもらえますか？   \n",
       "1                                この記事では何について述べていますか？   \n",
       "2  Can you provide any images or examples of how ...   \n",
       "3  When did Sabrina Karl join the Investopedia st...   \n",
       "4  ¿Cómo podría un algoritmo de aprendizaje autom...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  コレクション: MongoDB はドキュメントをコレクションに保存します。 関係データベース...   \n",
       "1  ã\\x81\\x93ã\\x81®è¨\\x98äº\\x8bã\\x81§ã\\x81¯ã\\x80\\x...   \n",
       "2  We believe that everyone should be able to rea...   \n",
       "3  Sabrina Karl joined the Investopedia staff in ...   \n",
       "4  Una cohort es un grupo de personas que compart...   \n",
       "\n",
       "                                              answer         label  \\\n",
       "0  申し訳ありませんが、この文脈からは視覚的な図を提供することはできません。コレクションは関係デ...       factual   \n",
       "1                                機能の可用性に地域差がある機能の一覧。       factual   \n",
       "2  Based on the incomplete context provided, I ca...       factual   \n",
       "3                                         April 2023       factual   \n",
       "4  El algoritmo podría utilizar técnicas de apren...  hallucinated   \n",
       "\n",
       "                                         explanation human_label  \n",
       "0  The query asks for a visual representation of ...     factual  \n",
       "1  The query asks what the article is about. The ...         NaN  \n",
       "2  The query asks for images or examples of how l...     factual  \n",
       "3  To determine if the answer is factual or hallu...     factual  \n",
       "4  The query asks how a machine learning algorith...     factual  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_df = pd.DataFrame(parsed_data)\n",
    "parsed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Walk through all subdirectories in labeled_datasets\n",
    "for root, dirs, files in os.walk('labeled_datasets'):\n",
    "    # Process only CSV files\n",
    "    csv_files = [f for f in files if f.endswith('.csv')]\n",
    "    \n",
    "    for csv_file in tqdm(csv_files, desc=f\"Processing CSV files in {root}\"):\n",
    "        # Get full path to CSV file\n",
    "        csv_path = os.path.join(root, csv_file)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(csv_path, low_memory=False)\n",
    "        \n",
    "        # Create a merge key for both dataframes\n",
    "        parsed_df['merge_key'] = parsed_df['question'] + parsed_df['reference'] + parsed_df['answer'] + parsed_df['label']\n",
    "        df['merge_key'] = df['input'] + df['reference'] + df['output'] + df['label']\n",
    "        \n",
    "        # Merge the human_label column based on the merge key\n",
    "        df = df.merge(\n",
    "            parsed_df[['merge_key', 'human_label']], \n",
    "            on='merge_key',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Drop the temporary merge key\n",
    "        df.drop('merge_key', axis=1, inplace=True)\n",
    "        \n",
    "        # Save back to CSV in same location\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Updated {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total language counts:\n",
      "language\n",
      "en    53961\n",
      "pt     7518\n",
      "ja     7414\n",
      "ko     1164\n",
      "es      984\n",
      "fr      974\n",
      "zh      140\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total rows across both files: 72155\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "non_synthetic_df = pd.read_csv('combined_datasets_for_evals/non_synthetic_hallucinations_all_languages.csv', low_memory=False)\n",
    "synthetic_df = pd.read_csv('combined_datasets_for_evals/synthetic_hallucinations_all_languages.csv', low_memory=False)\n",
    "\n",
    "# Combine dataframes\n",
    "combined_df = pd.concat([non_synthetic_df, synthetic_df])\n",
    "\n",
    "# Get total language counts across both datasets\n",
    "print(\"Total language counts:\")\n",
    "print(combined_df['language'].value_counts())\n",
    "print(f\"\\nTotal rows across both files: {len(combined_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of files merged: 198\n",
      "Total number of rows: 133761\n",
      "Number of unique rows: 48335\n",
      "\n",
      "Files included:\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/ja/docs_databricks_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/ja/www_mongodb_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/ja/experienceleague_adobe_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/pt/experienceleague_adobe_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/pt/www_mongodb_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/pt/docs_databricks_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/ko/experienceleague_adobe_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/fr/experienceleague_adobe_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/es/experienceleague_adobe_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_es.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/docs_databricks_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/medlineplus_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_law_cornell_edu_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/earthobservatory_nasa_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/pmc_ncbi_nlm_nih_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_investopedia_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_ncbi_nlm_nih_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_noaa_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/earthobservatory_nasa_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_mongodb_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/experienceleague_adobe_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_noaa_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_investopedia_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/medlineplus_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_law_cornell_edu_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_ncbi_nlm_nih_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/pmc_ncbi_nlm_nih_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/fr/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/fr/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/es/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/es/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/ja/www_mongodb_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/ja/experienceleague_adobe_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/ja/docs_databricks_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/pt/docs_databricks_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/pt/experienceleague_adobe_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/pt/www_mongodb_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/ko/experienceleague_adobe_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/fr/experienceleague_adobe_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/es/experienceleague_adobe_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_mongodb_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_noaa_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/pmc_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_law_cornell_edu_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/medlineplus_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/earthobservatory_nasa_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/earthobservatory_nasa_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_law_cornell_edu_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_investopedia_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_noaa_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/experienceleague_adobe_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_investopedia_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/medlineplus_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/docs_databricks_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/pmc_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_ja_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_ja_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question_old.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_ja_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question_old.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question_old.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question_old.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_pt_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_pt_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question_old.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question_old.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_pt_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/zh/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_zh_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_ko_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_question_old.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_ko_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/fr/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_fr_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/fr/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_question_old.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/fr/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/es/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_es_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/es/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_question_old.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/es/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question_old.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question_old.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question_old.csv\n",
      "- labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/ja/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/ja/docs_databricks_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/pt/www_mongodb_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/pt/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/pt/docs_databricks_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/ko/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/fr/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/es/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_noaa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_investopedia_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/earthobservatory_nasa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/docs_databricks_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/medlineplus_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/pmc_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/medlineplus_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/earthobservatory_nasa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_mongodb_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_noaa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_law_cornell_edu_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/pmc_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_law_cornell_edu_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_investopedia_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/docs_databricks_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/www_mongodb_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/fr/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/es/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_mongodb_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/docs_databricks_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "- labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# Get all CSV files recursively from labeled_datasets, excluding /old directory\n",
    "csv_files = []\n",
    "for root, dirs, files in os.walk('labeled_datasets'):\n",
    "    if 'old' in root:\n",
    "        continue\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            csv_files.append(os.path.join(root, file))\n",
    "\n",
    "# Read and combine all CSV files\n",
    "dfs = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file, low_memory=False)\n",
    "    dfs.append(df)\n",
    "    \n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Count unique rows based on input, output and reference columns\n",
    "unique_df = combined_df.drop_duplicates(subset=['input', 'output', 'reference', 'label'])\n",
    "\n",
    "print(f\"\\nTotal number of files merged: {len(csv_files)}\")\n",
    "print(f\"Total number of rows: {len(combined_df)}\")\n",
    "print(f\"Number of unique rows: {len(unique_df)}\")\n",
    "print(\"\\nFiles included:\")\n",
    "for f in csv_files:\n",
    "    print(f\"- {f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing 2 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows in international datasets: 48583\n",
      "Synthetic rows: 30509\n",
      "Non-synthetic rows: 18074\n",
      "Total rows with human labels: 7191\n",
      "Total rows with hallucination label: 48583\n",
      "Total rows with both human and hallucination labels: 7191\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read and combine the international datasets\n",
    "synthetic_path = 'combined_datasets_for_evals/synthetic_hallucinations_all_languages.csv'\n",
    "non_synthetic_path = 'combined_datasets_for_evals/non_synthetic_hallucinations_all_languages.csv'\n",
    "\n",
    "synthetic_df = pd.read_csv(synthetic_path, low_memory=False)\n",
    "non_synthetic_df = pd.read_csv(non_synthetic_path, low_memory=False)\n",
    "\n",
    "combined_df = pd.concat([synthetic_df, non_synthetic_df], ignore_index=True)\n",
    "\n",
    "print(f\"\\nTotal rows in international datasets: {len(combined_df)}\")\n",
    "print(f\"Synthetic rows: {len(synthetic_df)}\")\n",
    "print(f\"Non-synthetic rows: {len(non_synthetic_df)}\")\n",
    "\n",
    "print(f\"Total rows with human labels: {len(combined_df[combined_df['human_label'].notna()])}\")\n",
    "print(f\"Total rows with hallucination label: {len(combined_df[combined_df['label'].notna()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows in JSONL file: 24040\n",
      "Number of rows with duplicate prompts: 0\n",
      "Percentage of duplicates: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the JSONL file and convert to DataFrame\n",
    "jsonl_path = '/Users/jgilhuly/Documents/dev/GitHub/dataset-generation-research/file-6c389e02-8925-4b4e-ad77-2d3bc5eb6d94.jsonl'\n",
    "df = pd.read_json(jsonl_path, lines=True)\n",
    "\n",
    "# Count duplicate prompts\n",
    "duplicate_count = df['prompt'].duplicated().sum()\n",
    "total_rows = len(df)\n",
    "\n",
    "print(f\"\\nTotal rows in JSONL file: {total_rows}\")\n",
    "print(f\"Number of rows with duplicate prompts: {duplicate_count}\")\n",
    "print(f\"Percentage of duplicates: {(duplicate_count/total_rows)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 198 CSV files in the labeled_datasets directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading CSV files: 100%|██████████| 198/198 [00:02<00:00, 77.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows across all CSV files: 133761\n",
      "Number of duplicate rows: 59987\n",
      "Percentage of duplicates: 44.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   6%|▌         | 12/198 [00:00<00:03, 57.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 16 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/docs_databricks_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 28 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/earthobservatory_nasa_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 28 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/earthobservatory_nasa_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 7 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/experienceleague_adobe_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 163 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/medlineplus_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 155 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/medlineplus_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 11 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/pmc_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 11 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/pmc_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 22 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_investopedia_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 21 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_investopedia_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 103 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_law_cornell_edu_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 100 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_law_cornell_edu_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 20 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_mongodb_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  14%|█▍        | 28/198 [00:00<00:02, 71.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 88 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 90 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 115 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_noaa_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 115 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/en/www_noaa_gov_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 9 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/es/experienceleague_adobe_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_answer.csv\n",
      "Removed 3 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/fr/experienceleague_adobe_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_answer.csv\n",
      "Removed 6 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/ja/docs_databricks_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_answer.csv\n",
      "Removed 4 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/ja/experienceleague_adobe_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_answer.csv\n",
      "Removed 10 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/ja/www_mongodb_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_answer.csv\n",
      "Removed 6 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/ko/experienceleague_adobe_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_answer.csv\n",
      "Removed 16 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/pt/docs_databricks_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_answer.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/pt/experienceleague_adobe_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_answer.csv\n",
      "Removed 26 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/non_synthetic/pt/www_mongodb_com_claude_3_5_sonnet_latest_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_answer.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question_old.csv\n",
      "Removed 2 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  22%|██▏       | 44/198 [00:00<00:02, 70.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 209 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 209 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 9 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question_old.csv\n",
      "Removed 7 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "Removed 452 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 452 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 10 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "Removed 64 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 64 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 1 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "Removed 306 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 306 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 3 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  26%|██▋       | 52/198 [00:00<00:02, 63.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 315 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 315 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 40 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question_old.csv\n",
      "Removed 4 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "Removed 244 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 244 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 6 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "Removed 401 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 401 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 27 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_en_even.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/es/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_question.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/es/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_question_old.csv\n",
      "Removed 6 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/es/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_es_even.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/fr/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_question.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/fr/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_question_old.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  43%|████▎     | 86/198 [00:01<00:00, 116.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 6 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/fr/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_fr_even.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question_old.csv\n",
      "Removed 6 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_ja_even.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question_old.csv\n",
      "Removed 4 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_ja_even.csv\n",
      "Removed 1 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question_old.csv\n",
      "Removed 3 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_ja_even.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_question.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_question_old.csv\n",
      "Removed 4 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_ko_even.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_ko_even.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question_old.csv\n",
      "Removed 6 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/docs_databricks_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_pt_even.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question_old.csv\n",
      "Removed 2 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/experienceleague_adobe_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_pt_even.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question_old.csv\n",
      "Removed 13 duplicates from ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_pt_even.csv\n",
      "No duplicates found in ./labeled_datasets/claude-3-5-sonnet-latest-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/zh/www_mongodb_com_claude_3_5_sonnet_latest_synthetic_mistral_large_latest_gpt_4o_zh_even.csv\n",
      "Removed 22 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/docs_databricks_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 67 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/earthobservatory_nasa_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 67 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/earthobservatory_nasa_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 7 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/experienceleague_adobe_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 69 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/medlineplus_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 70 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/medlineplus_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  50%|█████     | 99/198 [00:01<00:01, 91.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 22 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/pmc_ncbi_nlm_nih_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 22 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/pmc_ncbi_nlm_nih_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 93 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_investopedia_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 94 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_investopedia_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 123 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_law_cornell_edu_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 125 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_law_cornell_edu_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 47 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_mongodb_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 90 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_ncbi_nlm_nih_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 90 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_ncbi_nlm_nih_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 147 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_noaa_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 148 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/en/www_noaa_gov_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 9 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/es/experienceleague_adobe_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_es.csv\n",
      "Removed 6 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/fr/experienceleague_adobe_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  56%|█████▌    | 110/198 [00:01<00:01, 84.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 3 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/ja/docs_databricks_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja.csv\n",
      "Removed 10 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/ja/experienceleague_adobe_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja.csv\n",
      "Removed 7 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/ja/www_mongodb_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/ko/experienceleague_adobe_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko.csv\n",
      "Removed 3 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/pt/docs_databricks_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt.csv\n",
      "Removed 7 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/pt/experienceleague_adobe_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt.csv\n",
      "Removed 51 duplicates from ./labeled_datasets/gpt-4o-hallucinations/non_synthetic/pt/www_mongodb_com_gpt_4o_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt.csv\n",
      "Removed 15 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 1024 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 1024 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 5 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 1016 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  61%|██████    | 120/198 [00:01<00:01, 75.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1016 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 191 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 192 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 1021 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 1023 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 1025 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 1030 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 18 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 1025 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  70%|███████   | 139/198 [00:01<00:00, 71.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1024 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 597 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 597 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 3 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/es/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_answer.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/es/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_question.csv\n",
      "Removed 2 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/fr/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_answer.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/fr/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_question.csv\n",
      "Removed 1 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_answer.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "Removed 2 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_answer.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "Removed 2 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_answer.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_answer.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_question.csv\n",
      "Removed 5 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_answer.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/docs_databricks_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "Removed 1 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_answer.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/experienceleague_adobe_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "Removed 29 duplicates from ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_answer.csv\n",
      "No duplicates found in ./labeled_datasets/gpt-4o-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/www_mongodb_com_gpt_4o_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  80%|████████  | 159/198 [00:02<00:00, 67.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 86 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/docs_databricks_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 464 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/earthobservatory_nasa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 460 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/earthobservatory_nasa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 26 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 4122 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/medlineplus_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 4082 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/medlineplus_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 88 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/pmc_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 85 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/pmc_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 374 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_investopedia_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 366 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_investopedia_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 559 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_law_cornell_edu_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 550 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_law_cornell_edu_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 80 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_mongodb_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 5286 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n",
      "Removed 5291 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 3861 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_noaa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  88%|████████▊ | 174/198 [00:02<00:00, 51.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 3850 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/en/www_noaa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 16 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/es/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_question.csv\n",
      "Removed 15 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/fr/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_question.csv\n",
      "Removed 2398 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/ja/docs_databricks_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja.csv\n",
      "Removed 8 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/ja/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "Removed 25 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/ko/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_question.csv\n",
      "Removed 106 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/pt/docs_databricks_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "Removed 31 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/pt/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "Removed 88 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/non_synthetic/pt/www_mongodb_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_non_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "Removed 60 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/docs_databricks_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  91%|█████████ | 180/198 [00:02<00:00, 46.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 320 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 316 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/earthobservatory_nasa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 12 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 998 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 994 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/medlineplus_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 81 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 85 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/pmc_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 373 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 381 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_investopedia_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  96%|█████████▋| 191/198 [00:03<00:00, 41.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 426 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 428 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_law_cornell_edu_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 47 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_mongodb_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 836 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 828 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_ncbi_nlm_nih_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n",
      "Removed 764 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_answer.csv\n",
      "Removed 759 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/en/www_noaa_gov_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_en_question.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 198/198 [00:03<00:00, 63.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 7 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/es/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_es_question.csv\n",
      "Removed 9 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/fr/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_fr_question.csv\n",
      "Removed 8 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ja/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_ja_question.csv\n",
      "Removed 21 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/ko/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_ko_question.csv\n",
      "Removed 89 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/docs_databricks_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "Removed 37 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/experienceleague_adobe_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "Removed 46 duplicates from ./labeled_datasets/litellm/together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-hallucinations/synthetic/even-split-of-hallucinations-and-factuals/pt/www_mongodb_com_litellm_together_ai_meta_llama_Meta_Llama_3.1_8B_Instruct_Turbo_synthetic_gpt_4o_claude_3_5_sonnet_latest_pt_question.csv\n",
      "\n",
      "Duplicate removal complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to find all CSV files in a directory recursively\n",
    "def find_csv_files(directory):\n",
    "    csv_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Skip the 'old' directory\n",
    "        if 'old' in root.split(os.sep):\n",
    "            continue\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                csv_files.append(os.path.join(root, file))\n",
    "    return csv_files\n",
    "\n",
    "# Get all CSV files in the labeled_datasets directory\n",
    "csv_files = find_csv_files('./labeled_datasets/')\n",
    "print(f\"Found {len(csv_files)} CSV files in the labeled_datasets directory\")\n",
    "\n",
    "# Read all CSV files into a list of DataFrames\n",
    "all_dfs = []\n",
    "for file_path in tqdm(csv_files, desc=\"Reading CSV files\"):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        df['source_file'] = file_path  # Add source file information\n",
    "        all_dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "if not all_dfs:\n",
    "    print(\"No valid CSV files found or all files had errors.\")\n",
    "else:\n",
    "    # Combine all DataFrames\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    \n",
    "    # Check for duplicates based on content (excluding the source_file column)\n",
    "    content_columns = [col for col in combined_df.columns if col != 'source_file']\n",
    "    duplicated_mask = combined_df.duplicated(subset=content_columns, keep='first')\n",
    "    duplicate_count = duplicated_mask.sum()\n",
    "    \n",
    "    print(f\"\\nTotal rows across all CSV files: {len(combined_df)}\")\n",
    "    print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "    print(f\"Percentage of duplicates: {(duplicate_count/len(combined_df))*100:.2f}%\")\n",
    "    \n",
    "    # Ask user if they want to remove duplicates\n",
    "    user_input = input(\"\\nDo you want to remove duplicates from the CSV files? (yes/no): \")\n",
    "    \n",
    "    if user_input.lower() in ['yes', 'y']:\n",
    "        # Group by source file and remove duplicates\n",
    "        file_groups = combined_df.groupby('source_file')\n",
    "        \n",
    "        for file_path, group_df in tqdm(file_groups, desc=\"Processing files\"):\n",
    "            # Get the original DataFrame for this file\n",
    "            original_df = group_df.drop(columns=['source_file'])\n",
    "            \n",
    "            # Find duplicates within this file\n",
    "            duplicates_in_file = original_df.duplicated(keep='first')\n",
    "            duplicate_count_in_file = duplicates_in_file.sum()\n",
    "            \n",
    "            if duplicate_count_in_file > 0:\n",
    "                # Remove duplicates\n",
    "                deduplicated_df = original_df.drop_duplicates(keep='first')\n",
    "                \n",
    "                # Write back to the file\n",
    "                deduplicated_df.to_csv(file_path, index=False)\n",
    "                print(f\"Removed {duplicate_count_in_file} duplicates from {file_path}\")\n",
    "            else:\n",
    "                print(f\"No duplicates found in {file_path}\")\n",
    "        \n",
    "        print(\"\\nDuplicate removal complete!\")\n",
    "    else:\n",
    "        print(\"\\nNo changes were made to the CSV files.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoenix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
